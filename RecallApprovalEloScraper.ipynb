{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ac023182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#⠀cata santos & mitchell esbenshade | BIOE 4350 | mini project 2.4⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡀⠀⠀⠀⢰⠂⠀⠀⠀⠀⠀⠀⠀\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠄⠀⠀⠀⠉⣷⠀⠀⢸⡄⠀⠀⠀⠀⠀⠀⠀\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢻⡄⠀⠀⠀⠀⣿⠀⠀⠈⣿⣦⣄⠀⠀⠀⠀⠀\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡸⣞⡇⠀⠀⠀⣼⡿⠀⠀⠀⠀⠉⠉⠀⠀⠀⠀⠀\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣧⢿⣽⡀⠀⠉⠛⠁⠀⣰⣾⠿⠿⣦⡀⠀⠀⠀⠀\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣼⣞⡿⣞⡅⠀⠀⠀⠀⠘⠏⠓⠒⠒⠀⠀⠀⠀⠀⠀\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣰⣟⢾⣽⢫⡿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣠⢤⣶⡻⣞⣿⣺⢯⣽⣳⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⢠⣄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣠⣤⣿⣽⣻⢾⣽⣷⣾⣽⣻⣞⣷⣳⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⠈⢻⣿⣶⣄⡀⠀⠀⠀⣀⣲⣴⢶⣞⡿⣽⣞⡷⣯⢿⡽⣞⣿⠟⠋⠁⠉⠈⠳⣟⣆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢻⣿⣿⣿⣿⢶⣾⣿⡽⣯⣟⡾⣽⡷⣯⣟⡽⡾⣽⡯⠁⠀⠀⠀⠀⠀⠀⢮⣭⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⢞⣿⣿⢯⡿⣿⣯⣟⣷⣯⢿⣳⣟⡷⣽⣼⣻⣽⠀⠀⠀⠀⠀⠀⠀⢀⣼⡯⡗⠋⠤⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢾⣿⣿⣯⣽⣾⣿⣾⣗⡿⣯⡷⣯⣟⡷⣞⣼⣿⣀⠀⠀⠀⠀⢀⣠⡿⣏⡗⠈⠐⠈⠅⠀⠀⠀⠀⠀⠀⠀\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣼⠛⠏⠉⠉⠽⢟⢿⣿⣿⣿⣿⣷⣻⢾⡽⣞⡷⠄⡹⣶⢿⣻⢿⣻⡽⢯⣼⢦⠶⠁⠈⠀⠀⠀⠀⠀⠀⠀\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣸⣯⠇⠀⠀⠀⠀⠀⠁⣽⣿⣿⣿⣷⣯⣿⣽⣛⡦⠀⠀⢩⣿⣹⢯⣷⢻⣟⠺⢣⡖⣘⠤⠓⠀⠀⠀⠀⠀⠀\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢈⣿⡃⠁⠀⠀⠀⢀⣤⣾⣟⢿⣻⣿⣿⣟⡾⣽⡳⠄⠎⢳⣯⢯⣟⡾⢯⣞⣯⣓⠉⢀⠀⠀⡄⢢⡀⠀⠀⠀\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣸⣷⣷⣶⣳⣶⣺⣿⣿⣳⢯⣟⣿⣿⣳⢯⠛⠅⠃⠀⠀⣴⣿⡿⣬⢶⠾⠙⣊⣥⠾⡒⠊⢁⢠⠣⣌⠀⠀⠀\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢺⡽⣾⡽⣯⣟⣿⡿⣯⣿⣿⣾⢿⣿⠳⢏⣈⢠⠀⠀⣰⢿⡿⣽⣉⡶⠌⠋⠉⣀⡀⠁⠀⠀⠀⣘⡐⣂⠀⠀\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⣽⣳⣟⣳⣟⣾⣽⣿⣿⣿⣿⣿⣦⣜⡻⡽⠆⠧⣴⡟⣯⢟⡳⣭⠲⠄⠐⠀⠀⠀⠈⠁⠉⠑⢊⡕⢃⠄⠀\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠹⣿⣾⣿⣯⣿⣾⣿⣿⣿⣿⣿⣿⣿⣿⣾⢧⠀⠹⠾⡵⡞⡽⢢⣃⠐⠀⠀⠄⡐⠀⠀⠀⡘⢦⠘⣌⠀⠀\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠐⠹⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⢯⡏⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⠒⡈⠀⡀⠄⡑⠢⣉⠴⣈⣆\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⠻⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⢯⣏⡴⣶⣵⣢⢤⢠⡀⡄⢠⠐⡰⢌⡱⠀⡁⡀⠆⡥⠆⡥⣛⡽⣾\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡀⠔⠉⠀⠀⢽⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣼⣻⢷⣯⡽⣞⣷⣻⡼⣡⢋⡔⠣⠜⡐⢐⠠⡓⣤⣙⣲⣽⣻⢷\n",
    "#⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣷⡿⣽⣞⣷⣻⡴⣣⢜⡱⣊⡕⣊⠠⡙⡰⣭⢷⣯⣿⢿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fde02dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------> initialize libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from urllib.request import urlretrieve\n",
    "from zipfile import ZipFile\n",
    "import ijson\n",
    "import numpy as np\n",
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7bd71b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIP already downloaded.\n",
      "JSON already extracted.\n",
      "Parsed 56382 recalls\n"
     ]
    }
   ],
   "source": [
    "# -----------------------> Download and extract FDA recall JSON\n",
    "url = \"https://download.open.fda.gov/device/recall/device-recall-0001-of-0001.json.zip\"\n",
    "zip_filename = \"device-recall-0001-of-0001.json.zip\"\n",
    "json_filename = \"device-recall-0001-of-0001.json\"\n",
    "\n",
    "if not os.path.exists(zip_filename):\n",
    "    print(\"Downloading FDA recall zip...\")\n",
    "    urlretrieve(url, zip_filename)\n",
    "else:\n",
    "    print(\"ZIP already downloaded.\")\n",
    "\n",
    "if not os.path.exists(json_filename):\n",
    "    print(\"Extracting JSON...\")\n",
    "    with ZipFile(zip_filename, 'r') as z:\n",
    "        z.extract(json_filename)\n",
    "else:\n",
    "    print(\"JSON already extracted.\")\n",
    "\n",
    "# -----------------------> Parse recall JSON streaming bo use less memory\n",
    "records = []\n",
    "with open(json_filename, 'r', encoding='utf-8') as f:\n",
    "    parser = ijson.items(f, 'results.item')\n",
    "    for entry in parser:\n",
    "        manufacturer = entry.get('recalling_firm', '').strip() or \"Unknown\"\n",
    "\n",
    "        recall_status = entry.get('recall_status', '').strip().lower()\n",
    "        if 'terminated' in recall_status:\n",
    "            rating = 1000\n",
    "        elif 'completed' in recall_status:\n",
    "            rating = 800\n",
    "        elif 'ongoing' in recall_status:\n",
    "            rating = 500\n",
    "        elif 'pending' in recall_status:\n",
    "            rating = 300\n",
    "        else:\n",
    "            rating = 600\n",
    "\n",
    "        records.append({\n",
    "            'manufacturer': manufacturer,\n",
    "            'product_description': entry.get('product_description', '').replace('\\n',' ').strip(),\n",
    "            'recall_status': recall_status,\n",
    "            'reason_for_recall': entry.get('reason_for_recall','').replace('\\n',' ').strip(),\n",
    "            'event_date_initiated': entry.get('event_date_initiated',''),\n",
    "            'recall_number': entry.get('recall_number','').strip(),\n",
    "            'rating': rating\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "print(f\"Parsed {len(df)} recalls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dd9a70e8-805f-4530-a024-c8eda0a8e4e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved raw recalls to recalls_with_ratings_summary.xlsx\n"
     ]
    }
   ],
   "source": [
    "# -----------------------> Save Raw Recalls Sheet\n",
    "output_file = \"recalls_with_ratings_summary.xlsx\"\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    df.to_excel(writer, sheet_name=\"Raw_Recalls\", index=False)\n",
    "\n",
    "print(f\"Saved raw recalls to {output_file}\") #save columns w/ manufacturer name (mult. instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a6c6c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------> Aggregate per manufacturer\n",
    "short=pd.DataFrame({\n",
    "    'Company Nicknames': df['manufacturer'].astype(str).str.slice(0,4) # grab first 4 letters of each company\n",
    "})\n",
    "df.agg(total_recalls=('manufacturer','count'), avg_rating=('rating', 'mean'))\n",
    "df.reset_index()\n",
    "df['manufacturer']=short['Company Nicknames']\n",
    "output=df.groupby('manufacturer', as_index=False)['rating'].sum()\n",
    "output=output.sort_values('rating', ascending=False)\n",
    "output.to_excel(output_file, sheet_name=\"Manufacturer_Summary\", index=False) \n",
    "#saved new sheet in workbook with shortened names + rating combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9c8fdea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------> Compute ELO-style score\n",
    "newdf= pd.read_excel('recalls_with_ratings_summary.xlsx', sheet_name = 'Manufacturer_Summary')\n",
    "avg_rating = newdf['rating'].mean()\n",
    "newdf['elo'] = 1000 - 0.04 * (newdf['rating'] - rating) # k value arbitrary, company rating compared to average rating, 1000 gives us chess-style looking number\n",
    "#hieuristics mostly here, vibes-based coding for decision on k-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ea1b69a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------> Add rating category\n",
    "percentiles = summary_df['elo'].rank(pct=True)\n",
    "conditions = [\n",
    "    percentiles >= 0.8,\n",
    "    (percentiles >= 0.6) & (percentiles < 0.8),\n",
    "    (percentiles >= 0.4) & (percentiles < 0.6),\n",
    "    (percentiles >= 0.2) & (percentiles < 0.4),\n",
    "    percentiles < 0.2\n",
    "]\n",
    "ratings = ['Excellent', 'Great', 'Average', 'Poor', 'Avoid']\n",
    "summary_df['Rating_Category'] = np.select(conditions, ratings, default='Unrated').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f371d2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use market value to affect elo ranking & factor into conditions ^^ bc that is jank\n",
    "#Manually making a dataframe, but trust thia data is sorted based on market value & search analytics\n",
    "topcomp={\n",
    "        'tier1': ['john', 'abbo', 'medt'],\n",
    "        'tier2': ['Intu', 'Stry', 'Bost', 'Bect', 'Dana', 'GE H', 'Baxt', 'Zimm', 'Edwa', 'Alig', 'Holo', 'ICU', 'ResM', 'Coop', 'Dexc', 'Insu', 'Tele', 'West', 'Henr', 'Patt'],\n",
    "        'tier3': ['Abio', 'CONM', 'Glob', 'NuVa', 'STER', 'Haem', 'Inte', 'Masi', 'iRhy', 'Shoc', 'Penu', 'Axon', 'Tran', 'Tand', 'Envi', 'Neog', 'Seml', 'Angi', 'Atri', 'Cute', 'Sien', 'Surm', 'Tact', 'Vera', 'ZimV'],\n",
    "        'tier4': ['Acce','Apyx','Arti','AxoG','CVRx','Cyte','Dari','Earg','Esta','Glau','InMo','Insp','Liva','Natu','Nevr','Orth','Pulm','SeaS','Ster','Trea', 'Vare'],\n",
    "        'tier5': ['Stry', 'Exac', 'Butt', 'Outs', 'Proc', 'CVRx', 'Hear', 'Veri', 'GRAI', 'Temp', '23an', 'Guar', 'Thri', 'Carb', 'Vari', 'Cryo', 'LeMa', 'RTI', 'Tiss', 'Avan','Meri', 'Orth', 'Acce', 'Alco', 'Baus', 'Hang', 'Lant', 'Neva', 'Sigh', 'Zoll']\n",
    "}\n",
    "max_length = max(len(topcomp['tier1']), len(topcomp['tier2']), len(topcomp['tier3']), len(topcomp['tier4']), len(topcomp['tier5']))\n",
    "\n",
    "# Pad all lists to the same length with np.nan\n",
    "for tier in topcomp:\n",
    "    current_length = len(topcomp[tier])\n",
    "    if current_length < max_length:\n",
    "        topcomp[tier].extend([np.nan] * (max_length - current_length))\n",
    "\n",
    "# Create DataFrame\n",
    "topcomp = pd.DataFrame(topcomp)\n",
    "\n",
    "#ideally, import both as dataframes, then use comparison to parse into tiers of companies\n",
    "tier1=set(topcomp['tier1'])\n",
    "tier2=set(topcomp['tier2'])\n",
    "tier3=set(topcomp['tier3'])\n",
    "tier4=set(topcomp['tier4'])\n",
    "tier5=set(topcomp['tier5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "50913d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5 tier columns: ['tier1', 'tier2', 'tier3', 'tier4', 'tier5']\n"
     ]
    }
   ],
   "source": [
    "tier_columns = [col for col in topcomp.columns if 'tier' in col.lower()]\n",
    "print(f\"Processing {len(tier_columns)} tier columns: {tier_columns}\")\n",
    "    \n",
    "for col in tier_columns:\n",
    "    topcomp[col] = topcomp[col].astype(str).str.strip().str.lower()\n",
    "    topcomp[col] = topcomp[col].replace('nan', '')\n",
    "    \n",
    "    # Create tier sets\n",
    "tier_sets = {}\n",
    "for col in tier_columns:\n",
    "     companies = set([c for c in topcomp[col] if c and c != 'nan'])\n",
    "     tier_sets[col] = companies\n",
    "\n",
    "\n",
    "if 'summary_df' in locals() and hasattr(summary_df, 'columns'):\n",
    "     compare = summary_df[['Company_Short']].copy()\n",
    "\n",
    "compare['Company_Short_Clean'] = compare['Company_Short'].astype(str).str.strip().str.lower()\n",
    "    \n",
    "def find_tier(company):\n",
    "     for tier_name, tier_set in tier_sets.items():\n",
    "           if company in tier_set:\n",
    "             return tier_name\n",
    "     return 'unknown_tier'\n",
    "    \n",
    "results_df = pd.DataFrame()\n",
    "results_df['Matched_Tier'] = compare['Company_Short_Clean'].apply(find_tier)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9b114514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We did it joe! saved to sorted_by_tier.xlsx\n"
     ]
    }
   ],
   "source": [
    "# -----------------------> Export Excel\n",
    "output_file = \"sorted_by_tier.xlsx\"\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    summary_df.to_excel(writer, sheet_name=\"Recalls_Only\", index=False)\n",
    "    results_df.to_excel(writer, sheet_name='Recalls_Only', index=False)\n",
    "\n",
    "df = pd.read_excel('rankedcompanies_elovsrelevancy.xlsx', sheet_name='Recalls_Only')\n",
    "\n",
    "# Define the custom sorting order for tiers\n",
    "tier_order = ['tier1', 'tier2', 'tier3', 'tier4', 'tier5', 'unknown_tier']\n",
    "\n",
    "# Convert to categorical with custom order\n",
    "df['Matched_Tier'] = pd.Categorical(df['Matched_Tier'], categories=tier_order, ordered=True)\n",
    "\n",
    "# Sort by tier\n",
    "df_sorted = df.sort_values('Matched_Tier')\n",
    "\n",
    "# Save the sorted dataframe\n",
    "df_sorted.to_excel('sorted_by_tier.xlsx', index=False)\n",
    "\n",
    "print(f\"We did it joe! saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa2b815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
